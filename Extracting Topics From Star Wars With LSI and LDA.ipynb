{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set number of topics for LSI/LDA\n",
    "nTopics = 8\n",
    "\n",
    "# Set subject of the analysis\n",
    "subject = 'Star Wars Episode IV'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To store data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To plot graphs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import rgb2hex\n",
    "\n",
    "# To create nicer graphs\n",
    "import seaborn as sns\n",
    "\n",
    "# To create interactive graphs\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, plot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# To vectorize texts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# To decompose texts\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "# To visualize high dimensional dataset\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# To tag words\n",
    "from textblob import TextBlob\n",
    "\n",
    "# To use new datatypes\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Shape: (1010, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Did you hear that?  They've shut down the main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>We're doomed!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>There'll be no escape for the Princess this time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>What's that?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>I should have known better than to trust the l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character                                               text\n",
       "1  THREEPIO  Did you hear that?  They've shut down the main...\n",
       "2  THREEPIO                                      We're doomed!\n",
       "3  THREEPIO  There'll be no escape for the Princess this time.\n",
       "4  THREEPIO                                       What's that?\n",
       "5  THREEPIO  I should have known better than to trust the l..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('../star-wars-movie-scripts/SW_EpisodeIV.txt', delim_whitespace=True, header=0, escapechar='\\\\').rename(columns={'dialogue':'text'})\n",
    "print('DataFrame Shape: {}'.format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Vectorized Text: (1010, 1581)\n"
     ]
    }
   ],
   "source": [
    "# Create vectorizer\n",
    "countVectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Vectorize text\n",
    "vectorizedText = countVectorizer.fit_transform(df['text'].str.replace(\"'\", '').values)\n",
    "print('Shape Vectorized Text: {}'.format(vectorizedText.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot n Most Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot n most frequent words\n",
    "n = 20\n",
    "\n",
    "\n",
    "\n",
    "def nMostFrequentWords(n, countVectorizer, vectorizedText):    \n",
    "    # Count word appearences in text\n",
    "    vectorizedCount = np.sum(vectorizedText, axis=0)\n",
    "    \n",
    "    # Get word indices and counts\n",
    "    wordIndices = np.flip(np.argsort(vectorizedCount), 1)\n",
    "    wordCounts = np.flip(np.sort(vectorizedCount),1)\n",
    "\n",
    "    # Create wordvectors to inverse-transform them\n",
    "    wordVectors = np.zeros((n, vectorizedText.shape[1]))\n",
    "    for i in range(n):\n",
    "        wordVectors[i, wordIndices[0,i]] = 1\n",
    "\n",
    "    # Inverse-transfrom the wordvectors\n",
    "    words = [word[0].encode('ascii').decode('utf-8') for word in countVectorizer.inverse_transform(wordVectors)]\n",
    "\n",
    "    # Return word and word-counts\n",
    "    return (words, wordCounts[0, :n].tolist()[0])\n",
    "\n",
    "\n",
    "\n",
    "# Get most frequent words with wordcounts\n",
    "words, wordCounts = nMostFrequentWords(n=n, countVectorizer=countVectorizer, vectorizedText=vectorizedText)\n",
    "\n",
    "# Create colormap\n",
    "cmap = get_cmap('viridis')\n",
    "colors = [rgb2hex(cmap(color)) for color in np.arange(0, 1.000001, 1/(n-1))]\n",
    "\n",
    "# Create plot\n",
    "data = go.Bar(x = words,\n",
    "              y = wordCounts,\n",
    "              marker = dict(color = colors))\n",
    "\n",
    "layout = go.Layout(title = 'Most Frequent {} Words In {}'.format(n, subject),\n",
    "                   xaxis = dict(title = 'Words'),\n",
    "                   yaxis = dict(title = 'Count'))\n",
    "\n",
    "fig = go.Figure(data=[data], layout=layout)\n",
    "_ = plot(fig, filename='build/Most Frequent {} Words In {}.html'.format(n, subject), auto_open=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tags and descriptions\n",
    "tag_dict = {'CC':'conjunction, coordinating; and, or, but',\n",
    "                'CD':'cardinal number; five, three, 13%',\n",
    "                'DT':'determiner; the, a, these',\n",
    "                'EX':'existential there; there were six boys',\n",
    "                'FW':'foreign word; mais',\n",
    "                'IN':'conjunction, subordinating or preposition; of, on, before, unless',\n",
    "                'JJ':'adjective; nice, easy',\n",
    "                'JJR':'adjective, comparative; nicer, easier',\n",
    "                'JJS':'adjective, superlative; nicest, easiest',\n",
    "                'LS':'list item marker; ',\n",
    "                'MD':'verb, modal auxillary; may, should',\n",
    "                'NN':'noun, singular or mass; tiger, chair, laughter',\n",
    "                'NNS':'noun, plural; tigers, chairs, insects',\n",
    "                'NNP':'noun, proper singular; Germany, God, Alice',\n",
    "                'NNPS':'noun, proper plural; we met two Christmases ago',\n",
    "                'PDT':'predeterminer; both his children',\n",
    "                'POS':\"possessive ending; 's\",\n",
    "                'PRP':'pronoun, personal; me, you, it',\n",
    "                'PRP$':'pronoun, possessive; my, your, our',\n",
    "                'RB':'adverb; extremely, loudly, hard',\n",
    "                'RBR':'adverb, comparative; better',\n",
    "                'RBS':'adverb, superlative; best',\n",
    "                'RP':'adverb, particle; about, off, up',\n",
    "                'SYM':'symbol; %',\n",
    "                'TO':'infinitival to; what to do?',\n",
    "                'UH':'interjection; oh, oops, gosh',\n",
    "                'VB':'verb, base form; think',\n",
    "                'VBZ':'verb, 3rd person singular present; she thinks',\n",
    "                'VBP':'verb, non-3rd person singular present; I think',\n",
    "                'VBD':'verb, past tense; they thought',\n",
    "                'VBN':'verb, past participle; a sunken ship',\n",
    "                'VBG':'verb, gerund or present participle; thinking is fun',\n",
    "                'WDT':'wh-determiner; which, whatever, whichever',\n",
    "                'WP':'wh-pronoun, personal; what, who, whom',\n",
    "                'WP$':'wh-pronoun, possessive; whose, whosever',\n",
    "                'WRB':'wh-adverb; where, when'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tag-function to DataFrame, stack tags and count them\n",
    "tag_df = pd.DataFrame.from_records(df['text'].apply(lambda x: [tag for word, tag in TextBlob(x).pos_tags]).tolist()).stack().value_counts().reset_index().rename(columns={'index':'tag', 0:'count'})\n",
    "\n",
    "\n",
    "# Create colormap\n",
    "n = tag_df.shape[0]\n",
    "cmap = get_cmap('viridis')\n",
    "colors = [rgb2hex(cmap(color)) for color in np.arange(0, 1.000001, 1/(n-1))]\n",
    "\n",
    "# Create plot\n",
    "data = go.Bar(x = tag_df['tag'],\n",
    "              y = tag_df['count'],\n",
    "              text = tag_df['tag'].apply(lambda x: tag_dict[x] if x in tag_dict.keys() else x),\n",
    "              marker = dict(color = colors))\n",
    "\n",
    "layout = go.Layout(title = 'Most Frequent Tags In {}'.format(subject),\n",
    "                   xaxis = dict(title = 'Type Of Word'),\n",
    "                   yaxis = dict(title = 'Count'))\n",
    "\n",
    "fig = go.Figure(data=[data], layout=layout)\n",
    "_ = plot(fig, filename='build/Most Frequent Tags In {}.html'.format(subject), auto_open=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing/Analysis LSI/LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape LSI Topic Matrix: (1010, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create LSI and fit\n",
    "lsiModel = TruncatedSVD(n_components=nTopics)\n",
    "lsiTopicMatrix = lsiModel.fit_transform(vectorizedText)\n",
    "print('Shape LSI Topic Matrix: {}'.format(lsiTopicMatrix.shape))\n",
    "\n",
    "# Get most probable keys and all categories with counts\n",
    "lsiKeys = lsiTopicMatrix.argmax(axis=1)\n",
    "lsiCategories, lsiCounts = zip(*Counter(lsiKeys).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTopWords(n, lsiKeys, vectorizedText, countVectorizer):\n",
    "    # Create empty array for sum\n",
    "    wordSum = np.zeros((nTopics, vectorizedText.shape[1]))\n",
    "\n",
    "    # Iterate over the topic of each word\n",
    "    for i, key in enumerate(lsiKeys):\n",
    "        # Sum the vectors of each topic\n",
    "        wordSum[key] += vectorizedText[i]\n",
    "    \n",
    "    # Sort and get the most frequent n words for each topic\n",
    "    topWordsIndices = np.flip(np.argsort(wordSum, axis=1)[:, -n:], axis=1)\n",
    "\n",
    "\n",
    "    # Store all words for all topics\n",
    "    topWords = []\n",
    "\n",
    "    # Iterate over the topics with its indices\n",
    "    for topic in topWordsIndices:\n",
    "        # Store all words for one topic\n",
    "        topicWords = []\n",
    "\n",
    "        # Iterate over the indices for the topic\n",
    "        for index in topic:\n",
    "            # Create a wordvector for the index\n",
    "            wordVector = np.zeros((vectorizedText.shape[1]))\n",
    "            wordVector[index] = 1\n",
    "            # Inverse-transfor the wordvector\n",
    "            word = countVectorizer.inverse_transform(wordVector)[0][0]\n",
    "            # Store the word\n",
    "            topicWords.append(word.encode('ascii').decode('utf-8'))\n",
    "        # Store all words for the topic\n",
    "        topWords.append(', '.join(topicWords))\n",
    "\n",
    "    return topWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: going, dont, know, youre, think\n",
      "Topic 1: im, going, level, detention, trying\n",
      "Topic 2: wan, obi, help, kenobi, alderaan\n",
      "Topic 3: luke, hold, force, pull, hurry\n",
      "Topic 4: dont, sir, worry, forget, like\n",
      "Topic 5: right, got, ive, just, ill\n",
      "Topic 6: come, red, threepio, standing, leader\n",
      "Topic 7: ship, station, rebel, time, power\n"
     ]
    }
   ],
   "source": [
    "# Get top n words\n",
    "topWords = getTopWords(5, lsiKeys, vectorizedText, countVectorizer)\n",
    "\n",
    "# Print the topics and its words\n",
    "for i, words in enumerate(topWords):\n",
    "    print('Topic {}: {}'.format(i, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data\n",
    "lsiCategoriesSorted, lsiCountsSorted = zip(*sorted(zip(lsiCategories, lsiCounts)))\n",
    "\n",
    "# Create labels\n",
    "topWords = getTopWords(3, lsiKeys, vectorizedText, countVectorizer)\n",
    "labels = ['Topic {}'.format(i) for i in lsiCategoriesSorted]\n",
    "\n",
    "# Create colormap\n",
    "n = nTopics\n",
    "cmap = get_cmap('viridis')\n",
    "colors = [rgb2hex(cmap(color)) for color in np.arange(0, 1.000001, 1/(n-1))]\n",
    "\n",
    "# Create plot\n",
    "data = go.Bar(x = labels,\n",
    "              y = lsiCountsSorted,\n",
    "              text = topWords,\n",
    "              marker = dict(color = colors))\n",
    "\n",
    "layout = go.Layout(title = 'Most Frequent LSI Topics In {}'.format(subject),\n",
    "                   xaxis = dict(title = 'Topic'),\n",
    "                   yaxis = dict(title = 'Count'))\n",
    "\n",
    "fig = go.Figure(data=[data], layout=layout)\n",
    "_ = plot(fig, filename='build/Most Frequent LSI Topics In {}.html'.format(subject), auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 1010 samples in 0.003s...\n",
      "[t-SNE] Computed neighbors for 1010 samples in 0.099s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1010\n",
      "[t-SNE] Computed conditional probabilities for sample 1010 / 1010\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 64.524857\n",
      "[t-SNE] Error after 2000 iterations: 0.504664\n"
     ]
    }
   ],
   "source": [
    "# Transform high dimensional dataset to visualize in 2D\n",
    "tsneModel = TSNE(n_components=2, perplexity=50, learning_rate=100, n_iter=2000, verbose=1, random_state=0, angle=0.75)\n",
    "tsneModelVectors = tsneModel.fit_transform(lsiTopicMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMeanVectors(keys, twoDVectors):\n",
    "    # Store vectorsum\n",
    "    meanTopicVectors = np.zeros((nTopics, 2))\n",
    "    # Store vectorcoutn\n",
    "    topicCount = np.zeros(nTopics)\n",
    "\n",
    "    # Iterate over each key-vector pair\n",
    "    for key, tsneVector in zip(keys, twoDVectors):\n",
    "        # Sum and count the vectors\n",
    "        meanTopicVectors[key] += tsneVector\n",
    "        topicCount[key] += 1\n",
    "\n",
    "    # Return mean of the vectors\n",
    "    return meanTopicVectors / topicCount[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create colormap\n",
    "n = nTopics\n",
    "cmap = get_cmap('tab10')\n",
    "colors = [rgb2hex(cmap(color)) for color in np.arange(0, 1.000001, 1/(n-1))]\n",
    "\n",
    "# Get n top words\n",
    "topWords = getTopWords(3, lsiKeys, vectorizedText, countVectorizer)\n",
    "# Compute centers for topics\n",
    "lsiMeanTopicVectors = getMeanVectors(lsiKeys, tsneModelVectors)\n",
    "\n",
    "\n",
    "# Create plot\n",
    "data = []\n",
    "# Iterate over each topic\n",
    "for topic in range(nTopics):\n",
    "    # Mask for a single topic\n",
    "    mask = lsiKeys==topic\n",
    "    scatter = go.Scatter(x = tsneModelVectors[mask,0],\n",
    "                         y = tsneModelVectors[mask,1],\n",
    "                         name = 'Topic {}: {}'.format(topic, topWords[topic]),\n",
    "                         mode = 'markers',\n",
    "                         text = df[mask]['text'],\n",
    "                         marker = dict(color = colors[topic]))\n",
    "    data.append(scatter)\n",
    "\n",
    "layout = go.Layout(title = 't-SNE Clustering of {} LSI Topics'.format(nTopics),\n",
    "                   showlegend=True,\n",
    "                   hovermode = 'closest')\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "_ = plot(fig, filename='build/t-SNE Clustering of {} LSI Topics.html'.format(nTopics), auto_open=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape LSI Topic Matrix: (1010, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create LDA and fit\n",
    "ldaModel = LatentDirichletAllocation(n_components=nTopics, learning_method='online', random_state=0, verbose=0)\n",
    "ldaTopicMatrix = ldaModel.fit_transform(vectorizedText)\n",
    "print('Shape LSI Topic Matrix: {}'.format(ldaTopicMatrix.shape))\n",
    "\n",
    "# Get most probable keys and all categories with counts\n",
    "ldaKeys = ldaTopicMatrix.argmax(axis=1)\n",
    "ldaCategories, ldaCounts = zip(*Counter(ldaKeys).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: come, dont, red, good, theres\n",
      "Topic 1: hold, im, star, way, speed\n",
      "Topic 2: threepio, yes, wait, artoo, sand\n",
      "Topic 3: target, beam, ben, tractor, kenobi\n",
      "Topic 4: luke, going, im, youre, think\n",
      "Topic 5: station, hey, battle, away, vader\n",
      "Topic 6: know, dont, hes, sir, oh\n",
      "Topic 7: right, im, ill, ship, want\n"
     ]
    }
   ],
   "source": [
    "# Get top n words\n",
    "topWords = getTopWords(5, ldaKeys, vectorizedText, countVectorizer)\n",
    "\n",
    "# Print the topics and its words\n",
    "for i, words in enumerate(topWords):\n",
    "    print('Topic {}: {}'.format(i, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data\n",
    "ldaCategoriesSorted, ldaCountsSorted = zip(*sorted(zip(ldaCategories, ldaCounts)))\n",
    "\n",
    "# Create labels\n",
    "topWords = getTopWords(3, ldaKeys, vectorizedText, countVectorizer)\n",
    "labels = ['Topic {}'.format(i) for i in ldaCategoriesSorted]\n",
    "\n",
    "# Create colormap\n",
    "n = nTopics\n",
    "cmap = get_cmap('viridis')\n",
    "colors = [rgb2hex(cmap(color)) for color in np.arange(0, 1.000001, 1/(n-1))]\n",
    "\n",
    "# Create plot\n",
    "data = go.Bar(x = labels,\n",
    "              y = ldaCountsSorted,\n",
    "              text = topWords,\n",
    "              marker = dict(color = colors))\n",
    "\n",
    "layout = go.Layout(title = 'Most Frequent LDA Topics In {}'.format(subject),\n",
    "                   xaxis = dict(title = 'Topic'),\n",
    "                   yaxis = dict(title = 'Count'))\n",
    "\n",
    "fig = go.Figure(data=[data], layout=layout)\n",
    "_ = plot(fig, filename='build/Most Frequent LDA Topics In {}.html'.format(subject), auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 1010 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1010 samples in 0.121s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1010\n",
      "[t-SNE] Computed conditional probabilities for sample 1010 / 1010\n",
      "[t-SNE] Mean sigma: 0.099793\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 48.311043\n",
      "[t-SNE] Error after 1900 iterations: 0.251934\n"
     ]
    }
   ],
   "source": [
    "# Transform high dimensional dataset to visualize in 2D\n",
    "tsneModel = TSNE(n_components=2, perplexity=50, learning_rate=100, n_iter=2000, verbose=1, random_state=0, angle=0.75)\n",
    "tsneModelVectors = tsneModel.fit_transform(ldaTopicMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create colormap\n",
    "n = nTopics\n",
    "cmap = get_cmap('tab10')\n",
    "colors = [rgb2hex(cmap(color)) for color in np.arange(0, 1.000001, 1/(n-1))]\n",
    "\n",
    "# Get n top words\n",
    "topWords = getTopWords(3, ldaKeys, vectorizedText, countVectorizer)\n",
    "# Compute centers for topics\n",
    "ldaMeanTopicVectors = getMeanVectors(ldaKeys, tsneModelVectors)\n",
    "\n",
    "\n",
    "# Create plot\n",
    "data = []\n",
    "# Iterate over each topic\n",
    "for topic in range(nTopics):\n",
    "    # Mask for a single topic\n",
    "    mask = ldaKeys==topic\n",
    "    scatter = go.Scatter(x = tsneModelVectors[mask,0],\n",
    "                         y = tsneModelVectors[mask,1],\n",
    "                         name = 'Topic {}: {}'.format(topic, topWords[topic]),\n",
    "                         mode = 'markers',\n",
    "                         text = df[mask]['text'],\n",
    "                         marker = dict(color = colors[topic]))\n",
    "    data.append(scatter)\n",
    "\n",
    "layout = go.Layout(title = 't-SNE Clustering of {} LDA Topics'.format(nTopics),\n",
    "                   showlegend=True,\n",
    "                   hovermode = 'closest')\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "_ = plot(fig, filename='build/t-SNE Clustering of {} LDA Topics.html'.format(nTopics), auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
